{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.364781",
     "start_time": "2017-01-28T22:33:34.348792"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import ipdb\n",
    "#%pdb\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv, random, numpy as np\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import img_to_array, load_img, flip_axis, random_shift\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.382909",
     "start_time": "2017-01-28T22:33:34.367925"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#Paths\n",
    "PATH_TRAIN_FOLDER = 'Training_Data/Udacity_Training_Data/'\n",
    "PATH_VALIDATION1 = 'Training_Data/VAL_TRACK1/'\n",
    "PATH_VALIDATION2 = 'Training_Data/VAL_TRACK2/'\n",
    "FILENAME_CSV = 'driving_log.csv'\n",
    "\n",
    "#Image \n",
    "IMAGE_CUT_TOP_HEIGHT = 55\n",
    "IMAGE_CUT_DOWN_HEIGHT = 25\n",
    "IMAGE_RESIZE_WIDTH = 64\n",
    "IMAGE_RESIZE_HEIGHT = 64\n",
    "\n",
    "#Camera\n",
    "CAMERA_LEFT_RIGHT_OFFSET = 0.2\n",
    "\n",
    "#Chances for Augmentation\n",
    "CHANCES_SHIFT = 0.5\n",
    "CHANCES_FLIP = 0.5\n",
    "CHANCES_DARKEN = 0.5\n",
    "BRIGHTNESS_RANGE = 0.3\n",
    "\n",
    "#Further Parameters\n",
    "SPEED_MINIMUM = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.408584",
     "start_time": "2017-01-28T22:33:34.385896"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read CSV\n",
    "def read_csv(path):\n",
    "    X, y = [], [] \n",
    "    \n",
    "    csv = pd.read_csv(path)\n",
    "    \n",
    "    #Throw away slow instances\n",
    "    csv = csv[(csv['speed']>SPEED_MINIMUM)]\n",
    "\n",
    "    for index, row in csv.iterrows():\n",
    "        #center\n",
    "        X.append(row['center'].strip())\n",
    "        y.append(row['steering'])\n",
    "        #left\n",
    "        X.append(row['left'].strip())\n",
    "        y.append(row['steering']+CAMERA_LEFT_RIGHT_OFFSET)\n",
    "        #right\n",
    "        X.append(row['right'].strip())\n",
    "        y.append(row['steering']-CAMERA_LEFT_RIGHT_OFFSET)\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.434873",
     "start_time": "2017-01-28T22:33:34.411824"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Images\n",
    "\n",
    "def resize_and_normalize(img):\n",
    "    #printing out some stats and plotting\n",
    "    #print('This image is:', type(img), 'with dimesions:', img.shape)\n",
    "    #print(img)\n",
    "    #Cut Top and Bottom (sky and car)\n",
    "    #img_cut = img[IMAGE_CUT_TOP_HEIGHT:img.shape[0]-IMAGE_CUT_DOWN_HEIGHT, :, :]\n",
    "    \n",
    "    img_cut = img[IMAGE_CUT_TOP_HEIGHT:160-IMAGE_CUT_DOWN_HEIGHT, :, :]\n",
    "\n",
    "    #Resize to smaller image size\n",
    "    img_resize = cv2.resize(img_cut, (IMAGE_RESIZE_WIDTH, IMAGE_RESIZE_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "    #Normalizing to a range of -0.5 to +0.5\n",
    "    img_norm = (img_resize / 255. - .5).astype(np.float32)\n",
    "\n",
    "    return img_norm\n",
    "\n",
    "#image = cv2.imread(PATH_TRAIN_FOLDER+'IMG/center_2016_12_01_13_30_48_287.jpg')\n",
    "#plt.imshow(resize_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.490441",
     "start_time": "2017-01-28T22:33:34.443947"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def augmentation(path, steering, validation):    \n",
    "\n",
    "    #Load\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    #Augment\n",
    "    if not validation:\n",
    "        #Darken\n",
    "        if random.random() < CHANCES_DARKEN:\n",
    "            image = random_darken(image)\n",
    "\n",
    "        #Shift\n",
    "        if random.random() < CHANCES_SHIFT:\n",
    "            image = random_shift(image, 0, 0.2, 0, 1, 2)\n",
    "\n",
    "        #Flip\n",
    "        if random.random() < CHANCES_FLIP:\n",
    "            image = flip_axis(image,1)\n",
    "            steering = steering * -1    \n",
    "            \n",
    "    #Resize\n",
    "    image = resize_and_normalize(image)\n",
    "\n",
    "    \n",
    "    return image, steering\n",
    "    \n",
    "def random_darken(image):\n",
    "    \n",
    "    w = image.shape[0]\n",
    "    h = image.shape[1]\n",
    "    \n",
    "    # Convert the image to HSV\n",
    "    temp = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute a random brightness value and apply to the image\n",
    "    brightness = BRIGHTNESS_RANGE + np.random.uniform()\n",
    "    \n",
    "    # Create a random Box\n",
    "    x1, y1 = random.randint(0, w), random.randint(0, h)\n",
    "    x2, y2 = random.randint(x1, w), random.randint(y1, h)\n",
    "    for i in range(x1, x2):\n",
    "        for j in range(y1, y2):\n",
    "            temp[i,j, 2] = temp[i, j, 2] * brightness\n",
    "\n",
    "    # Convert back to RGB and return\n",
    "    return cv2.cvtColor(temp, cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-28T22:33:34.526208",
     "start_time": "2017-01-28T22:33:34.499077"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "def model(load, shape, checkpoint=None):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, activation='elu', input_shape=shape))\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    model.add(Convolution2D(32, 5, 5, activation='elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Convolution2D(32, 5, 5, activation='elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(MaxPooling2D())\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024, activation='elu'))\n",
    "    model.add(Dense(512, activation='elu'))\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #NVIDIA-Model\n",
    "# def model(load, shape, checkpoint=None):\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Convolution2D(24, 5, 5,subsample=(2, 2), activation='elu', input_shape=shape))\n",
    "#     model.add(Convolution2D(36, 5, 5,subsample=(2, 2), activation='elu'))\n",
    "#     model.add(Convolution2D(48, 5, 5,subsample=(2, 2), activation='elu'))\n",
    "#     model.add(Convolution2D(64, 3, 3,activation='elu'))\n",
    "#     model.add(Convolution2D(64, 3, 3,activation='elu'))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(100, activation='elu'))\n",
    "#     model.add(Dense(50, activation='elu'))\n",
    "#     model.add(Dense(10, activation='elu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "#     model.compile(loss='mse', optimizer=\"adam\")\n",
    "    \n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the [NVIDIA-Architecture](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf):\n",
    "![image alt >](res/nvidia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-01-28T21:33:34.373Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _generator(batch_size, X, y, path, validation=False):\n",
    "    \"\"\"Generate batches of training data forever.\"\"\"\n",
    "    \n",
    "    while 1:\n",
    "        batch_X, batch_y = [], []\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            sample_index = random.randint(0, len(X) - 1)\n",
    "            sa = y[sample_index]       \n",
    "            \n",
    "            image, sa = augmentation(path+X[sample_index], sa, validation)\n",
    "            batch_X.append(image)\n",
    "            batch_y.append(sa)\n",
    "        yield np.array(batch_X), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(net):\n",
    "    net.save('model.h5')\n",
    "    \n",
    "    json_string = net.to_json()\n",
    "    with open('model.json', 'w') as outfile:\n",
    "        outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net,X, y, path):\n",
    "\n",
    "    net.fit_generator(_generator(256, X, y, path), samples_per_epoch=21990, nb_epoch=8)\n",
    "    save_model(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(net,X, y, path):\n",
    "    return net.evaluate_generator(_generator(256, X, y, path, validation=True), val_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_drivinig():\n",
    "    #Build model\n",
    "    net = model(load=False, shape=(IMAGE_RESIZE_WIDTH, IMAGE_RESIZE_HEIGHT, 3))\n",
    "    \n",
    "    #Read data and train test split them\n",
    "    X,y = read_csv(PATH_TRAIN_FOLDER+FILENAME_CSV)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #Training\n",
    "    train(net, X_train, y_train, PATH_TRAIN_FOLDER)\n",
    "    \n",
    "    #Evaluation - Testset\n",
    "    loss = evaluate(net, X_test, y_test, PATH_TRAIN_FOLDER)\n",
    "    print(\"Evaluation - Testset: {}\".format(loss))\n",
    "    \n",
    "    #Evaluation - Validation-Test#1\n",
    "    X_test,y_test = read_csv(PATH_VALIDATION1+FILENAME_CSV)\n",
    "    loss = evaluate(net, X_test, y_test, PATH_VALIDATION1)\n",
    "    print(\"Evaluation - Validation-Test#1: {}\".format(loss))\n",
    "        \n",
    "    #Evaluation - Validation-Test#2\n",
    "    X_test,y_test = read_csv(PATH_VALIDATION2+FILENAME_CSV)\n",
    "    loss = evaluate(net, X_test, y_test, PATH_VALIDATION2)\n",
    "    print(\"Evaluation - Validation-Test#2: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_checker():\n",
    "    print(\"*------- STANDARD ---------*\")\n",
    "    learn_drivinig()\n",
    "    \n",
    "    #Camera\n",
    "    CAMERA_LEFT_RIGHT_OFFSET = 0.1\n",
    "    print(\"*------- CAMERA_LEFT_RIGHT_OFFSET = 0.1 ---------*\")\n",
    "    learn_drivinig()\n",
    "    \n",
    "    #Camera\n",
    "    CAMERA_LEFT_RIGHT_OFFSET = 0.3\n",
    "    print(\"*------- CAMERA_LEFT_RIGHT_OFFSET = 0.3 ---------*\")\n",
    "    learn_drivinig()\n",
    "    \n",
    "    #resest\n",
    "    CAMERA_LEFT_RIGHT_OFFSET = 0.2\n",
    "    \n",
    "    #Image \n",
    "    IMAGE_CUT_TOP_HEIGHT = 65\n",
    "    IMAGE_CUT_DOWN_HEIGHT = 35 \n",
    "    print(\"*------- IMAGE_CUT_TOP_HEIGHT = 65 \\nIMAGE_CUT_DOWN_HEIGHT = 35  ---------*\")\n",
    "    learn_drivinig()\n",
    "    \n",
    "    #Image \n",
    "    IMAGE_CUT_TOP_HEIGHT = 45\n",
    "    IMAGE_CUT_DOWN_HEIGHT = 15 \n",
    "    print(\"*------- IMAGE_CUT_TOP_HEIGHT = 45 \\nIMAGE_CUT_DOWN_HEIGHT = 15 ---------*\")\n",
    "    learn_drivinig()  \n",
    "    \n",
    "    #reset\n",
    "    IMAGE_CUT_TOP_HEIGHT = 55\n",
    "    IMAGE_CUT_DOWN_HEIGHT = 25 \n",
    "    \n",
    "    IMAGE_RESIZE_WIDTH = 64\n",
    "    IMAGE_RESIZE_HEIGHT = 64\n",
    "    print(\"*------- IMAGE_RESIZE_WIDTH = 64 \\nIMAGE_RESIZE_HEIGHT = 64 ---------*\")\n",
    "    learn_drivinig()  \n",
    "    \n",
    "    IMAGE_RESIZE_WIDTH = 32\n",
    "    IMAGE_RESIZE_HEIGHT = 32\n",
    "    print(\"*------- IMAGE_RESIZE_WIDTH = 32 \\nIMAGE_RESIZE_HEIGHT = 32 ---------*\")\n",
    "    learn_drivinig()  \n",
    "    \n",
    "    #reset\n",
    "    IMAGE_RESIZE_WIDTH = 100\n",
    "    IMAGE_RESIZE_HEIGHT = 100\n",
    "    \n",
    "    #NoAugmentation\n",
    "    CHANCES_SHIFT = 0.0\n",
    "    CHANCES_FLIP = 0.0\n",
    "    CHANCES_DARKEN = 0.0\n",
    "    print(\"*------- No Augmentation ---------*\")\n",
    "    learn_drivinig()  \n",
    "    \n",
    "    #reset\n",
    "    CHANCES_SHIFT = 0.5\n",
    "    CHANCES_FLIP = 0.5\n",
    "    CHANCES_DARKEN = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-01-28T21:33:34.380Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Filter must not be larger than the input: Filter: (3, 3) Input: (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c1e87688fa9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#parameter_checker()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlearn_drivinig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-2656b1dfce44>\u001b[0m in \u001b[0;36mlearn_drivinig\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlearn_drivinig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_RESIZE_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_RESIZE_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Read data and train test split them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-b6086eaf4bb4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(load, shape, checkpoint)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    310\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 raise Exception('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;31m# this will call layer.build() if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0minput_added\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape if exception is raised by get_output_shape_for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    464\u001b[0m                           \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                           \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                           filter_shape=self.W_shape)\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_ordering\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'th'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, border_mode, dim_ordering, image_shape, filter_shape, filter_dilation)\u001b[0m\n\u001b[1;32m   1637\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilter_dilation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mfilter_dilation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfilter_dilation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    395\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2310\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1703\u001b[0m                          % op.type)\n\u001b[0;32m-> 1704\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mconv2d_shape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    244\u001b[0m   out_rows, out_cols = get2d_conv_output_size(in_rows, in_cols, filter_rows,\n\u001b[1;32m    245\u001b[0m                                               \u001b[0mfilter_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                                               padding)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mget2d_conv_output_size\u001b[0;34m(input_height, input_width, filter_height, filter_width, row_stride, col_stride, padding_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m   return get_conv_output_size((input_height, input_width),\n\u001b[1;32m    183\u001b[0m                               \u001b[0;34m(\u001b[0m\u001b[0mfilter_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                               (row_stride, col_stride), padding_type)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/weedjo/anaconda3/envs/CarND-TensorFlow-Lab/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mget_conv_output_size\u001b[0;34m(input_size, filter_size, strides, padding_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m          zip(filter_size, input_size)):\n\u001b[1;32m    148\u001b[0m     raise ValueError(\"Filter must not be larger than the input: \"\n\u001b[0;32m--> 149\u001b[0;31m                      \"Filter: %r Input: %r\" % (filter_size, input_size))\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpadding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"VALID\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Filter must not be larger than the input: Filter: (3, 3) Input: (1, 1)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':   \n",
    "    #parameter_checker()\n",
    "    learn_drivinig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('model.json', 'r') as jfile:\n",
    "          model = model_from_json(jfile.read())\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_model = model(load=False, shape=(100,100,3))\n",
    "n_model.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
